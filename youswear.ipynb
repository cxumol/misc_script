{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMra9eg/UnAvLsNBj2fWvR8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## sync version\n",
        "import re\n",
        "import pandas as pd\n",
        "import urllib.parse\n",
        "from datetime import datetime\n",
        "import requests as rq\n",
        "import sqlite3\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, RetryError\n",
        "from tdqm import tqdm\n",
        "\n",
        "BASE=\"https://www.youswear.com/index.asp\"\n",
        "\n",
        "def before_sleep_callback(retry_state):\n",
        "    print(f\"Attempt {retry_state.attempt_number} failed. Retrying...\")\n",
        "    if retry_state.outcome.exception():\n",
        "        print(f\"  Error: {retry_state.outcome.exception()}\")\n",
        "\n",
        "retry_strategy = retry(\n",
        "    stop=stop_after_attempt(5),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=10),\n",
        "    before_sleep=before_sleep_callback\n",
        ")\n",
        "\n",
        "@retry_strategy\n",
        "def get_with_retry(url):\n",
        "    return rq.get(url)\n",
        "\n",
        "\n",
        "languages : list = re.findall( r'class=\"list-group-item\">(.*?)</a></li>', get_with_retry(BASE).text)\n",
        "df = pd.DataFrame(columns=[\"language\", \"phrase\", \"meaning\", \"voteup\", \"votedown\"])\n",
        "for lang in tqdm(languages):\n",
        "    try:\n",
        "        html = get_with_retry(BASE + \"?language=\" + urllib.parse.quote_plus(lang)).text\n",
        "    except Exception as e:\n",
        "        print(\"Error getting ?language=\"+lang)\n",
        "        continue\n",
        "    try:\n",
        "        rows = re.findall(r'<tr>\\s+<td>(.*?)</td>\\s+<td>(.*?)</td>\\s+<td>.*?votefor.*?</a>.*?(\\d+).*?<a.*?voteagainst.*?</a>.*?(\\d+).*?</span>\\s+</td>', html,re.S)\n",
        "    except Exception as e:\n",
        "        print(\"Error parsing ?language=\"+lang)\n",
        "        continue\n",
        "    rows = [{\"language\": lang, \"phrase\": row[0], \"meaning\": row[1], \"voteup\": row[2], \"votedown\": row[3]} for row in rows]\n",
        "    df = pd.concat([df, pd.DataFrame(rows)])\n",
        "\n",
        "df.to_csv(\"youswear.csv\", index=False)\n",
        "df_csv = df.copy()\n",
        "\n",
        "# db_file = \"youswear.sqlite.db\"\n",
        "# conn = sqlite3.connect(db_file)\n",
        "# df.to_sql(\"swear\", conn, if_exists=\"replace\", index=False)\n",
        "# conn.commit()\n",
        "# conn.close()\n",
        "\n",
        "languages_df = df[[\"language\"]].drop_duplicates().reset_index(drop=True)\n",
        "languages_df[\"language_id\"] = languages_df.index + 1\n",
        "language_id_mapping = languages_df.set_index(\"language\")[\"language_id\"].to_dict()\n",
        "df[\"language_id\"] = df[\"language\"].map(language_id_mapping)\n",
        "df = df.drop(columns=[\"language\"])\n",
        "# df = df.rename(columns={\"language_id\":\"language\"})\n",
        "df = df[[\"language_id\", \"phrase\", \"meaning\", \"voteup\", \"votedown\"]]\n",
        "\n",
        "db_file = \"youswear.sqlite.db\"\n",
        "conn = sqlite3.connect(db_file)\n",
        "\n",
        "conn.executescript('''\n",
        "    PRAGMA foreign_keys = ON;\n",
        "    CREATE TABLE IF NOT EXISTS languages (\n",
        "        language_id INTEGER PRIMARY KEY,\n",
        "        language TEXT UNIQUE\n",
        "    );\n",
        "    CREATE TABLE IF NOT EXISTS swear (\n",
        "        language_id INTEGER,\n",
        "        phrase TEXT,\n",
        "        meaning TEXT,\n",
        "        voteup INTEGER,\n",
        "        votedown INTEGER,\n",
        "        FOREIGN KEY (language_id) REFERENCES languages(language_id)\n",
        "    );\n",
        "''')\n",
        "languages_df.to_sql(\"languages\", conn, if_exists=\"replace\", index=False)\n",
        "df.to_sql(\"swear\", conn, if_exists=\"replace\", index=False)\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "8toUBOtmOP0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## adds / update the column \"region\" in table \"languages\" by LLM classifier\n",
        "import sqlite3\n",
        "import json\n",
        "import requests as rq\n",
        "from tenacity import retry, stop_after_attempt, wait_exponential, before_sleep_log, RetryError\n",
        "from tqdm import tqdm\n",
        "import logging\n",
        "\n",
        "# API Configuration\n",
        "BASE = \"https://api.example/v1\"\n",
        "KEY = \"sk-no-need\"\n",
        "MODEL = \"THUDM/glm-4-9b-chat\"\n",
        "\n",
        "# Configure logging for tenacity\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "def before_sleep_callback(retry_state):\n",
        "    logger.warning(f\"Attempt {retry_state.attempt_number} failed. Retrying...\")\n",
        "    if retry_state.outcome.exception():\n",
        "        logger.warning(f\"  Error: {retry_state.outcome.exception()}\")\n",
        "\n",
        "retry_strategy = retry(\n",
        "    stop=stop_after_attempt(5),\n",
        "    wait=wait_exponential(multiplier=1, min=1, max=10),\n",
        "    before_sleep=before_sleep_callback\n",
        ")\n",
        "\n",
        "@retry_strategy\n",
        "def get_llm_response(messages):\n",
        "    res = rq.post(\n",
        "        BASE + \"/chat/completions\",\n",
        "        headers={\"Authorization\": \"Bearer \" + KEY, \"Content-Type\": \"application/json\"},\n",
        "        json={\"model\": MODEL, \"messages\": messages},\n",
        "        timeout=30\n",
        "    )\n",
        "    res.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "    return res.json()\n",
        "\n",
        "def extract_json_string(s, b='{', e='}'):\n",
        "    try:\n",
        "        i,j = s.rfind(b.strip()), s.rfind(e.strip())\n",
        "        if i == -1 or j == -1 or i >= j:\n",
        "            raise ValueError(\"No valid JSON object found\")\n",
        "        return s[i:j + len(e.strip())]\n",
        "    except ValueError as e:\n",
        "        raise ValueError(f\"Error extracting JSON: {e} from string: {s}\")\n",
        "\n",
        "@retry(stop=stop_after_attempt(5), before_sleep=before_sleep_log(logger, logging.WARNING))\n",
        "def get_regions_for_languages(languages):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Assistant is a classifier that returns in specified JSON format.\"},\n",
        "        {\"role\": \"user\", \"content\": (\n",
        "        \"Classify the following languages into their corresponding UN geographical subregions. \"\n",
        "        \"Return a JSON object where keys are the language names and values are the subregion names. \"\n",
        "        \"If a language does not have a corresponding UN region (e.g., it's fictional, it's animal, etc.), use `null` as the value.\\n\\n\"\n",
        "        \"<example>\\n\"\n",
        "        'Input: [\"Yoruba\",\"Guoyu\",\"Inuktitut\",\"Klingon\",\"Goose\",\"Turkey\",\"Alien\"]\\n'\n",
        "        'Output: {\"Yoruba\":\"Western Africa\",\"Guoyu\":\"Eastern Asia\",\"Inuktitut\":\"Northern America\",\"Klingon\":null,\"Goose\":null,\"Turkey\":\"Western Asia\",\"Alien\":null}\\n</example>\\n'\n",
        "        f'Input: {json.dumps(languages)}\\n'\n",
        "        \"Output:\"\n",
        "        )},\n",
        "    ]\n",
        "\n",
        "    response = get_llm_response(messages)\n",
        "    response_content = response[\"choices\"][0][\"message\"][\"content\"]\n",
        "    json_string = extract_json_string(response_content)\n",
        "    return json.loads(json_string)\n",
        "\n",
        "##  -- main --\n",
        "\n",
        "db_file = \"youswear.sqlite.db\"\n",
        "conn = sqlite3.connect(db_file)\n",
        "cursor = conn.cursor()\n",
        "\n",
        "try:\n",
        "    # Get all languages\n",
        "    cursor.execute(\"SELECT language FROM languages\")\n",
        "    languages = [row[0] for row in cursor.fetchall()]\n",
        "\n",
        "    # Group languages\n",
        "    group_size = 20\n",
        "    language_groups = [\n",
        "        languages[i:i + group_size] for i in range(0, len(languages), group_size)\n",
        "    ]\n",
        "\n",
        "    # Check if the 'region' column exists, add if not\n",
        "    cursor.execute(\"PRAGMA table_info(languages)\")\n",
        "    columns = [col[1] for col in cursor.fetchall()]\n",
        "    if \"region\" not in columns:\n",
        "        cursor.execute(\"ALTER TABLE languages ADD COLUMN region TEXT\")\n",
        "        conn.commit()\n",
        "\n",
        "    # Get regions and update database\n",
        "    for group in tqdm(language_groups, desc=\"Get regions and update database\"):\n",
        "        try:\n",
        "            regions_map = get_regions_for_languages(group)\n",
        "            for language, region in regions_map.items():\n",
        "                if region is not None:  # update only if region != NULL\n",
        "                    cursor.execute(\n",
        "                        \"UPDATE languages SET region = ? WHERE language = ?\",\n",
        "                        (region, language)\n",
        "                    )\n",
        "                else:\n",
        "                    logger.info(f\"Language '{language}' not mapped to a region.\")\n",
        "            conn.commit()\n",
        "        except RetryError as e:\n",
        "            logger.error(f\"Failed to process group after multiple retries: {group}. Error: {e}\")\n",
        "            continue # Continue to next group\n",
        "        except (ValueError, KeyError, rq.RequestException) as e:\n",
        "            logger.error(f\"Error processing group {group}: {e}\")\n",
        "            continue  # Continue processing other groups even if one fails.\n",
        "\n",
        "    cursor.execute(\"UPDATE languages SET region = NULL WHERE LOWER(region) IN ('undefined', 'null')\")\n",
        "    conn.commit()\n",
        "\n",
        "except sqlite3.Error as e:\n",
        "    print(f\"Database error: {e}\")\n",
        "finally:\n",
        "    conn.close()"
      ],
      "metadata": {
        "id": "fWTeSN1GthMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sql playground\n",
        "db_file = \"youswear.sqlite.db\"\n",
        "conn = sqlite3.connect(db_file)\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"PRAGMA table_info(languages)\")\n",
        "# print(cursor.fetchall())\n",
        "columns = [col[1] for col in cursor.fetchall()]\n",
        "print(columns)\n",
        "conn.commit()\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "72-DOLsM95HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "0AjcPGnIPVhY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hv6VV8u9PYz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-TBJ4pBM7AG"
      },
      "outputs": [],
      "source": [
        "## async version - too many HTTP 5xx errors\n",
        "import re\n",
        "import pandas as pd\n",
        "import urllib.parse\n",
        "from datetime import datetime\n",
        "import asyncio\n",
        "import httpx\n",
        "\n",
        "BASE = \"https://www.youswear.com/index.asp\"\n",
        "\n",
        "async def _web_scrape(lang: str, client: httpx.AsyncClient):\n",
        "    \"\"\"Fetches and processes data for a single language.\"\"\"\n",
        "    try:\n",
        "        url = BASE + \"?language=\" + urllib.parse.quote_plus(lang)\n",
        "        response = await client.get(url)\n",
        "        response.raise_for_status()  # Raise HTTPStatusError for bad responses (4xx or 5xx)\n",
        "        html = response.text\n",
        "    except httpx.RequestError as e:\n",
        "        print(f\"Error getting ?language={lang}: {e}\")\n",
        "        return []\n",
        "    except httpx.HTTPStatusError as e:\n",
        "        print(f\"HTTP error for ?language={lang}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(f\"General Error on request ?language={lang}: {e}\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        rows = re.findall(r'<tr>\\s+<td>(.*?)</td>\\s+<td>(.*?)</td>\\s+<td>.*?votefor.*?</a>.*?(\\d+).*?<a.*?voteagainst.*?</a>.*?(\\d+).*?</span>\\s+</td>', html, re.S)\n",
        "        return [{\"language\": lang, \"phrase\": row[0], \"meaning\": row[1], \"voteup\": row[2], \"votedown\": row[3]} for row in rows]\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing ?language={lang}: {e}\")\n",
        "        return []\n",
        "\n",
        "\n",
        "async def web_to_df():\n",
        "    \"\"\"Fetches data for all languages concurrently and creates a DataFrame.\"\"\"\n",
        "    async with httpx.AsyncClient() as client:\n",
        "        # Fetch available languages first\n",
        "        response = await client.get(BASE)\n",
        "        response.raise_for_status()\n",
        "        languages = re.findall(r'class=\"list-group-item\">(.*?)</a></li>', response.text)\n",
        "\n",
        "        # Gather data for all languages concurrently\n",
        "        tasks = [_web_scrape(lang, client) for lang in languages]\n",
        "        all_rows = await asyncio.gather(*tasks)\n",
        "\n",
        "    # Flatten the list of lists and create the DataFrame\n",
        "    df = pd.DataFrame([row for sublist in all_rows for row in sublist])\n",
        "    return df\n",
        "\n",
        "def save_df(df: pd.DataFrame, fbasename:str):\n",
        "    \"\"\"Saves the DataFrame to a CSV file.\"\"\"\n",
        "    df.to_csv(fbasename+\".csv\", index=False)\n",
        "\n",
        "    languages_df = df[[\"language\"]].drop_duplicates().reset_index(drop=True)\n",
        "    languages_df[\"language_id\"] = languages_df.index + 1\n",
        "    language_id_mapping = languages_df.set_index(\"language\")[\"language_id\"].to_dict()\n",
        "    df[\"language_id\"] = df[\"language\"].map(language_id_mapping)\n",
        "    df = df.drop(columns=[\"language\"])\n",
        "    df = df.rename(columns={\"language_id\":\"language\"})\n",
        "    df = df[[\"language\", \"phrase\", \"meaning\", \"voteup\", \"votedown\"]]\n",
        "\n",
        "    db_file = fbasename+\".sqlite.db\"\n",
        "    conn = sqlite3.connect(db_file)\n",
        "    languages_df.to_sql(\"languages\", conn, if_exists=\"replace\", index=False)\n",
        "    df.to_sql(\"swear\", conn, if_exists=\"replace\", index=False)\n",
        "    conn.executescript('''\n",
        "    PRAGMA foreign_keys = ON;\n",
        "    DROP TABLE IF EXISTS swear;\n",
        "    CREATE TABLE swear (\n",
        "        language INTEGER,\n",
        "        phrase TEXT,\n",
        "        meaning TEXT,\n",
        "        voteup INTEGER,\n",
        "        votedown INTEGER,\n",
        "        FOREIGN KEY (language) REFERENCES languages(language_id)\n",
        "    );\n",
        "    ''')\n",
        "    df.to_sql(\"swear\", conn, if_exists=\"append\", index=False)\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "\n",
        "def is_running_in_ipython():\n",
        "    \"\"\"Checks if the code is running in an IPython environment.\"\"\"\n",
        "    try:\n",
        "        from IPython import get_ipython\n",
        "        return get_ipython() is not None\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    if is_running_in_ipython():\n",
        "        import nest_asyncio\n",
        "        nest_asyncio.apply()\n",
        "    df = asyncio.run(web_to_df())\n",
        "    print(df)"
      ]
    }
  ]
}